Big Data C'est quoi ?
=====================
  C'est l'utilisation de gros volumes de donn√©es √† des fins de visualisation, d'analyse et de d√©cisions.

Big Data Pourquoi ?
===================
  - marketing (ciblage commercial)
  - finance (scoring des dossiers de cr√©dit)
  - d√©tection de fraude / anomalies
  - predictions

Les m√©tiers du Big Data
=======================

- Data Analyst : interrogation et visualisation de petit volumes de donn√©s, cr√©ation de rapports.
- Business Intelligence Developper : mise en place de la collecte, int√©gration et diffusion des donn√©s.
- Data Engineer : DevOps qui met en place l'infra BigData, facilite et optimise l'acc√®s au donn√©es.
- Data Architect: Data Engineer avanc√©, ayant des connaissances plus vaste et pointus, sur les architectures Big Data (clusters, ...).
- Data Scientist : transforme les donn√©es en informations qui ont de la valeur. C'est un Data Analyst dop√© au BigData et au Machine Learning.

Big Data Comment ?
==================

## Architecture Lambda #
Une architecture lambda se compose de 3 couches:
- batch layer
- speed layer
- serving layer

![lambda architecure](https://user.oc-static.com/upload/2017/12/14/15132725019668_lambda.jpeg "Architecture Lambda")

### Batch layer
Cette couche inclus :

- master Dataset (stockage des donn√©es brutes). C'est la source de v√©rit√©
- calculs distribu√©s

La master Dataset est contenu dans un data lake (gr√¢ce par ex. √† HDFS).
Afin d'√©viter la corruption des donn√©es, on stocke le sch√©ma des donn√©es avec elles.
ex: JSON n'inclus pas le sch√©ma alors que Apache Avro, oui.

### Serving layer
Cette couche doit supporter :

- √©criture par lot
- lecture al√©atoire

Techniquement, il s'agit d'une base NoSQL parmis Cassandra, MongoDb, ElascticSearch,...
Les base SQL ne passent pas √† l'√©chelle horizontalement, et les base cl√©/valeur n'ont pas (en g√©n√©ral) d'index.

La serving layer est un vue des donn√©es trait√©s par la batch layer.

### Speed layer

Dans cette couche, on stocke les donn√©es de fa√ßon d√©normalis√©es et aggr√©g√©s, pour un acc√®s rapide.
Les donn√©es sont effac√©es une fois disponibles, dans la serving layer.

## Base de donn√©es

D'apr√®s le th√©or√®me de CAP, formul√© par Eric A. Brewer :
> Dans toute base de donn√©es, vous ne pouvez respecter au plus que 2 propri√©t√©s parmi la coh√©rence, la disponibilit√© et la distribution.

![triangleCAP](https://user.oc-static.com/upload/2017/05/26/14958217637026_triangleCAP.png "Triangle de CAP")

### familles de bases NoSQL

- cl√©/valeur : utilis√© pour son efficacit√© et sa simplicit√©. Pas de langage de requ√™te, il faut conna√Ætre la cl√©. Utilisations : d√©tection de fraude en temps r√©el, IoT, e-commerce, gestion de cache, transactions rapides, fichiers de logs, chat.

- colonnes (HBase, Spark SQL, Elastic Search, ...) : utilis√© pour les traitements sur des colonnes comme les agr√©gats. Adapt√©e √† de gros calculs analytiques. Utilisations : Comptage (vote en ligne, compteur, etc), journalisation, recherche de produits dans une cat√©gorie, reporting √† large √©chelle.

- documents (MongoDB, Cassandra, ...): utilis√© pour manipuler des documents avec une structure complexe. Utilisations : gestion de contenu (biblioth√®ques num√©riques, collections de produits, d√©p√¥ts de logiciels, collections multim√©dia, etc.), framework stockant des objets, collection d‚Äô√©v√©nements complexes, gestion des historiques d‚Äôutilisateurs sur r√©seaux sociaux.

- graphes (Neo4j, OrientDB): utilis√© pour r√©soudre les probl√®mes de corr√©lations entre les √©l√©ments. Utilisations : r√©seaux sociaux (recommandation, plus court chemin, cluster...), r√©seaux SIG (routes, r√©seau √©lectrique, fret...), web social (Linked Data).


## Principaux langages utilis√©s ##

- R (implementation de S issue des laboratoires Bell) utilis√© par les statisticiens, data miner, data sctientist. N√© en 93, 1ere release en 1995. Avangtage: Simpmlicit√©, utilisation possbile de librairies Python. Inconveniant: mauvaises performances.
- Python. 1ere release 1991. Avantage: nombreuses biblioth√®ques de ML, ainsi qu'utilisation possible des bibliotheques R. Inconveniant : performance inf√©rieure √† Scala.
- Scala: 1ere release en 2004. Inconvenient: courbe d'aprentissage longue, avantage: performance

## Outillage ##

![Plan du paysage BigData](https://user.oc-static.com/upload/2017/03/20/14900195310816_Data-Platform-Map.jpeg)

- Rstudio (IDE pour R) execution sur un seul serveur
- Tensorflow (ML lib for Python)
- Apache Hadoop (applications distribu√©es)
- Apache Storm (traitement de flux distribu√©s)
- Apache Spark (calcul distribu√©) API: Scala, Java, Python, R, Javascript ( projet ind√©pendant [EclairJS](https://github.com/EclairJS/eclairjs) ). En moyenne 10x plus rapide que HDP Map Reduce et jusqu'√† 100x si la RAM peut absorber toutes les donn√©es.
- Apache Kafka Stream (pour des cas simples, pas de ML)

### Apache Storm
  
√âcrit en Clojure (dialect Lisp compilant en bytecode Java, javascript, ou bytecode .NET). Une *topology* (application Storm) traite des flux, en provenance de *Spouts* avec des *Bolts* (workers), ou des micro-batch (avec le plugin Trident).

## Fonctionnement de Spark ##

Spark fonctionne au sein d'un cluster de machines (ou containers).
Il a besoin d'un gestionnaire de ressources parmis : Spark Standalone, Apache YARN, Apache Mesos, k8s.
Spark est r√©parti entre un (ou plusieurs) driver et des workers
Le driver est responsable de l'execution d'une app (le main), et d√©legue l'execution des calculs (les fonctions) aux workers via les libs fournis.
Libs Spark: Spark SQL, Spark Streaming, Spark GraphX, Spark MLlib

## Se former ##

- Apprendre Scala : [Programming in Scala, 3rd Edition](https://libgen.pw/download/book/5a1f058c3a044650f51255eb)

- Aller plus loin, en Scala (Optionel) : [Functional programming in scala](https://libgen.pw/download/book/5a1f05453a044650f50e3aba)

- Prendre en main Spark : [Learning Spark: Lightning-Fast Big Data Analysis](https://libgen.pw/download/book/5a1f054d3a044650f50eb805)


Machine Learning (ML)
====================

## C'est quoi le ML ##

Cr√©ation d'un mod√®le √† partir d'un gros volume de donn√©es puis utilisation du mod√®le pour une pr√©diction quantitative (r√©gression), ou une pr√©diction qualitative (classification)

3 Types de mod√®les:

- Predictif : pr√©dire des √©venements futurs ou classifier des observations via apprentissage supervis√©.
- Descriptif : groupement des observations par similitudes via apprentissage non supervis√© (clustering).
- Adaptif : g√©n√©r√© via l'apprentissage par renforcement (un ou plusieurs agent de prise de d√©cision, qui recommendent ou ex√©cutent des actions)

Les mod√®les pr√©dictifs peuvent √™tre subdivis√© en 2 cat√©gories : 
- mod√®les g√©n√©ratifs (g√©n√©ralement introduit par la r√®gle de Bayes, fondation de la Classification Na√Øve Bay√©sienne)
- mod√®les discriminants


## Le clustering ##

Les algorithmes de clustering sont le plus souvent utilis√©s pour une analyse exploratoire des donn√©es.
Ils permettent, par exemple, d'identifier :
-  des clients qui ont des comportements similaires (segmentation de march√©)
-  des utilisateurs qui ont des usages similaires d'un outil
-  des communaut√©s dans des r√©seaux sociaux
-  des motifs r√©currents dans des transactions financi√®res.

On peut √©tablir la performance d'un clustering, en mesurant la s√©paration (S) inter-cluster (que l'on veut grande), et l'homog√©n√©it√© (T, pour tightness) intra-clusters (que l'on veut petite, c'est √† dire une petite distance entre les points).
On peut √©galement utiliser un seul crit√®re qui s'appuie sur S et T : l'indice de Davies-Bouldin (D).
Ou bien le coefficient de silhouette, qui d√©termine si chaque point est √† la fois proche des points du cluster auquel il appartient, et s'il est loin des points des autres clusters.

Une autre mesure √† prendre en compte et la stabilit√© des clusters.
Plusieurs ex√©cutions, avec des initialisations ou des sous-ensembles de donn√©es diff√©rents, donnent-elles les m√™mes r√©sultats ?

Le clustering hierarchique proc√®de par it√©ration, pour agglom√©rer (dans le cas d'un clustering agglom√©ratif) les clusters les plus proches (calcule de la distance via une m√©thode de lien, ou 'linkage method'), avec au d√©part, un cluster par point, pour obtenir un cluster pour tout les points. Dans le cas du clustering divisif, le processus est invers√©. Ce qui permet d'obtenir un arbre, repr√©sent√© par un dendogramme. Son co√ªt √©lev√© (quadratique), le r√©serve plut√¥t √† un petit jeu de donn√©es.

## Deep Learning ##

Le deep learning est une sp√©cialit√© du machine learning qui s'appuie sur les r√©seaux de neurones artificiels profonds, et des algorithmes d'analyse discriminante et apprenants. Profond car il s'agit d'un traitement multi-couche. Chaque couche correspondant √† un niveaux diff√©rent, d‚Äôabstraction des donn√©es.

Le perceptron multi-couche (ou multilayer perceptron, "MLP), permet de mod√©liser des fonctions complexes, en empilant des perceptrons (attribution de poids √† chaque variable, puis utilisation d'une fonction d'activation, sur la somme des variables pond√©r√©es).

### algo de deep learning ###

Le bagging (pour "bootstrap aggregation") utilise le m√©thode de bootstrap (g√©n√©ration de nouveau dataset par r√©enchantillonnage avec replacement), afin de combiner des apprenants faibles (mod√®le √† forte variance). Les diff√©rents peuvent √™tre cr√©√©s en parall√®le. Une pr√©diction est ensuite effectu√©e par un vote √† la majorit√© (classification), ou par une moyenne (r√©gression).
Il permet de r√©duire la variance des estimateurs, pour une meilleure performance et stabilit√©.

Les for√™ts al√©atoires utilise √©galement le bootstraping. Mais elles utilisent un sous-ensemble de features (d√©finition d'un hyperparam√®tre qui d√©termine le nombre de features √† utiliser pour chaque arbre) pour cr√©er chaque arbre de d√©cision.
Augmenter l'hyperparam√®tre permet de r√©duire la corr√©lation entre chaque arbre, pour de meilleures performances, mais au d√©triment de la vitesse d'√©x√©cution, puisque le mod√®le est plus complexe.

Le gradient boosting, est un m√©ta-algorithme (comme le bagging), qui va cr√©er des mod√®les de mani√®re s√©quentielle, par it√©ration. A chaque it√©ration, on applique une fonction de perte (pond√©ration des observations, pour l'adaboost), pour cr√©er un nouveau mod√®le plus performant.


Les r√©seaux de neurones r√©currents (Recurrent neural network, RNN) sont une famille de r√©seau de neurones qui traite les donn√©es de fa√ßon s√©quentielles. Prise en compte de l'√©tat pr√©ceant (complet), √† chaque nouvelle pr√©diction. Cette architecture pose des probl√®mes de gradient (disparition et explosion).
Pour palier les probl√®mes des RNN, il existe les LSTM Networks (Long Short Term Memory Networks). Ils utilisent des "gates" qui d√©terminent l'importance des entr√©es, pour enregister ou non, l'information qui en sort.

Les R√©seaux de neurones convolutifs (Convolutional Neural Network, CNN), sont utilis√©s pour le classement de donn√©es visuelles. Ils se constitue de 4 couches:
- convolution : rep√©rer la pr√©sence d'un ensemble de features
- pooling : r√©duction du nombre de param√®tres et de calculs dans le r√©seau.
- correction ReLU (Rectified Linear Units) : fonction d'activation
- fully connected : c'est la derni√®re couche dans tous les r√©seau de neurones. C'est somme des entr√©es pond√©r√©es, pass√© dans une fonction d'activation (logistique, si classification binaire, softmax, si classification mutli-classe)

Le Transfer Learning (ou apprentissage par transfert), permet de r√©utiliser un r√©seau pr√©-entrain√© (de pr√©f√©rence sur un probl√®me procher). Il peut exploiter un r√©seau suivant 3 strat√©gies :
- fine-tuning total : remplacement de la derni√®re couche (fully-connected) par un nouveau classifieur, puis entrainements de toutes les couches avec les nouvelles images. Utilisation avec une nouvelle collection de grande taille
- extractions de features : on retire la couche fully-connected, r√©utilisation des features, et on fixe les autres param√®tres. Utilis√© avec une petite collection, similaire.
- fine-tuning partiel : m√©lange des strat√©gies 1 et 2, en gardant certains param√®tres (couches basses). Utilis√© avec une petite collection, tr√®s diff√©rente.


## Algorithmes ##

- Supervis√©s : Apprentissage via un classement des donn√©es par l'humain
  * Arbre de d√©cision (Decision trees)
  * R√©seaux Bay√©siens (Bayesian network or Probabilistic DAG model)
  * M√©thodes des moindres carr√©s, permet d'effectuer principalement une Regression lin√©aire (Least squares)
  * Regression logistique (Logistic Regression) : classification binaire (en pourcentage de confiance). Idem r√©gression lin√©aire avec un facteur sigmoid en plus.
  * S√©parateurs √† vaste marge (SVM - Support Vector Machine) : classification binaire (bon pour classification non lin√©aire)
  * M√©thode des ensembles

- Non Supervis√©s: Apprentissage autonomne, sans retour humain. Cr√©ation de class par similitudes
  * Regroupement d'algorithmes
  * Analyse en composante principale (PCA - Principal component analysis) : d√©corr√©lation des variables (features) afin d'en r√©duire leur nombre.
  * t-SNE (t-distributed stochastic neighbor embedding) : permet de visualiser des donn√©es √† grandes dimensions non-lin√©aires sur 2 ou 3 dimensions, afin de rep√©rer des structures locales int√©ressantes pour le travail de mod√©lisation.
  * D√©composition en valeurs singuli√®re (SVD - Singular-value decomposition)
  * Analyse en composantes ind√©pendantes (ICA - Independent Component Analysis)
  * K-moyennes : Effectue une classification

Il existe aussi 2 autres familles d'algo, peu utilis√©s :
- semi-supervised learning : prend en entr√©e des donn√©es annot√©s, et d'autres non.
- reinforcement learning : bas√© sur un cycle exp√©reience / r√©compense. Am√©lioration √† chaque it√©ration.

### Utilisation des algo ###

#### Classification lin√©aire multi-classe ####

Il est possible d'utiliser un classifieur lin√©aire pour faire de la classification multi-classe.
Pour cela, on a 2 approches : 
- one-versus-rest (OVR ou OVA pour one-versus-all).
 On va cr√©er autant de classifieur que de classe en comparant chaque classe avec l'union des autres classes.
 On pr√©dit la classe pour laquelle la fonction de d√©cision est maximale.

- one-versus-one (OVO).
 On va cr√©er K(K -1) / 2 classifieurs, qui vont comparer chaque classe une √† une.
 On pr√©dit par un vote de la majorit√© (la classe pr√©dite par le plus grand nombre de classifieurs).


#### Utiliser un algo lin√©aire pour r√©soudre un probl√®me non-lin√©aire ####

On peut red√©crire les donn√©es dans un nouvel espace de redescription H (pour Hilbert) gr√¢ce √† une application [Œ¶](#Œ¶ "Phi"). L'espace de redescription sera g√©n√©ralement beaucoup plus grand que l'espace initial.

On peut √©galement utiliser l'astuce du noyau (kernel trick), not√© k,  afin d'√©viter le calcul de [Œ¶](#Œ¶ "Phi").
Il existe plusieurs types de noyaux (lin√©aire, polynomial, RBF, ...)

### Fonctionnement des algo ###


#### R√©gression lin√©aire ####

La r√©gression lin√©aire n'est pas un algo mais un type de mod√®le.

Ce type de mod√®le peut √™tre estim√© par :
- maximisation de vraissemblance
- m√©thode des moindres carr√©s (r√©duction du carr√© des erreurs)
- inf√©rence baysienne

Dans le cas le plus standard, on consid√®re les points ind√©pendants et identiquement distribu√©s (independent and identically distributed, i.i.d.).

Lorsque les variables sont corr√©l√©es, ou lorsqu'on a plus de variables que d'observations, on risque de faire du sur-apprentissage. Pour limiter ce risque, on va ajouter un hyperparam√®tre  : un coefficient de r√©gularisation. La r√©gularisation, consiste √† contr√¥ler simultan√©ment l'erreur du mod√®le sur le jeu d'entra√Ænement et la complexit√© du mod√®le.
Parmis les algo de r√©gularisation, on trouve :
- r√©gression ridge : r√©duit l'amplitude des coefficients d'une r√©gression lin√©aire
- lasso : annule certains coefficients
- elastic net : combinaison des 2 pr√©c√©dents

#### SVM ####

L'algo SVM pour "S√©paratrices √† vaste marge" ou "Machines √† Vecteurs de Support" ou "Support Vector Machine", aussi appel√© SVC pour "Support Vector Classification", est un algo de classification lin√©aire visant √† maximiser la marge entre chaque classe.
Il s'appuie sur les points (vecteurs de support) les plus proches de l'hyperplan s√©parateur.
Il existe 2 formulations permettant d'obtenir la SVM : 
- On optimise le primal si on a de faible dimensions.
- On optimise le dual si on a peu d'observations.

Il existe √©galement la r√©gression SVM aussi appel√©e SVR pour "Support Vector Regression" lorsqu'on l'utilise pour r√©soudre des probl√®mes de r√©gression.


#### K plus proches voisins (k-NN, k-nearest neighbors) ####

Algo de classification, peu utilis√©, car tr√®s co√ªteux. Il n√©cessite de garder en m√©moire toutes les observations (memory-based).
Il ne s'agit pas d'un algo param√©trique, donc pas d'apprentissage. Il associe √† une observation la m√™me √©tiquette que la majorit√© de ses k plus proches points d'entrainement. On fera varier k (hyperparam√®tre) pour obtenir la plus faible erreur.

Note: On parle d'hyperparam√®tre lorsqu'il s'agit d'un param√®tre de l'algorithme d'apprentissage, et de param√®tre (souvant not√© [ùúΩ](#ùúΩ "theta")), lorsqu'il s'agit d'un param√®tre du mod√®le, trouv√© par apprentissage.

#### K-moyennes (K-means) ####

Partionnement des observations en K partitions (clusters).
Chaque cluster poss√®de un Centroid qui est le barycentre de ses membres. Chaque centroid est recalcul√© de fa√ßon it√©rative (et chaque point r√©assign√© au centroid le plus proche), afin de minimis√© le total des distances de chaque point √† son centroid.
La phase d'initialisation des centroid peut-√™tre optimis√© via l'algo de Agha-Ashour.  De m√™me, le crit√®re de similarit√© (distance euclidienne vs cosinus) ne doit pas √™tre n√©glig√©. Il peut avoir un impact sur la densit√© du cluster.

#### DBSCAN ####

DBSCAN (Density-Based Spatial Clustering of Applications with Noise) partitionne les observations par densit√©. Pour chaque observation il construit son epsilon-voisinage. Si son Œµ-voisinage contient le minimum de voisins, chaque voisin est ajout√© au cluster. Sinon, il est consid√©r√© comme du bruit.

Inconv√©niants : 
- DBSCAN est difficile √† utiliser en tr√®s grande dimension
- le choix des param√®tres Œµ et n-min (nombre de voisins minimums) peut √™tre d√©licat.
- ne trouvera pas de cluster de densit√© diff√©rente

Avantages :
- efficace en temps de calcul
- pas besoin de pr√©difinir le nombre de clusters
- permet de trouver des cluster de forme arbitraire

#### Esp√©rance-maximisation (Expectation-maximization, EM) ####

Contrairement au K-means, il prends en compte (par d√©duction) les valeurs non observ√©s (latentes).
K-means is a special case of the EM for Gaussian mixtures.


#### Analyse en composantes principales (Principal components analysis, PCA) ####

Transforme et extrait les caract√©ristiques les plus critiques (en terme de variance).
Extrait les vecteurs et valeurs propres, √† partir de la matrice de covariance des observations. Puis les classes par valeurs propres (composante principale)
L'ACP cherche √† maximiser la variance de X selon des directions orthogonales.


#### kPCA ####

Utilise un noyau (kernel trick) pour permettre le plongement d'un algorithme lin√©aire dans une vari√©t√© non-lin√©aire. Rarement utilis√©e dans sa forme premi√®re : elle n√©cessite de garder en m√©moire la matrice K(x,y) (son stockage n√©cessite le carr√© de la taille des donn√©es).

#### Analyse factorielle ####

L'analyse factorielle cherche √† mod√©liser la structure de la covariance des variables observ√©es et ne d√©finit pas n√©cessairement des axes orthogonaux.

#### Na√Øve Bayes ####

L'inf√©rence bay√©sienne calcule les probabilit√©s de diverses causes hypoth√©tiques √† partir de l'observation des cons√©quences connues.
Le raisonnement bay√©sien interpr√®te la probabilit√© comme le degr√© de confiance a accorder √† une cause hypoth√©tique.

Na√Øve Bayes consid√®re chaque feature comme ind√©pendante.
Cette restriction est assouplie par le mod√®le Hidden Na√Øve Bayes (HNB), qui utilise l'information mutuelle conditionnelle, pour d√©crire l'interd√©pendance entre certaines features.

La Classification mutltinomiale na√Øve bay√©sienne est particuli√®rement adapt√© √† la fouille de textes (text mining).


#### Multivariate Bernoulli classification ####

idem Na√Øve bayes, mais au lieu d'ignorer l'abscence d'une observation dans une feature, il la p√©nalise.


## Workflow ##

### 1. Pr√©paration des donn√©es ###

#### Extracting features ####

A partir des donn√©es brutes, il faut obtenir des valeurs num√©riques.
Plusieurs m√©thodes existent, et d√©pendent de la nature des donn√©es (texte, image, ...)

Afin que chaque variable ait la m√™me importance, il faut standardiser chaque variable, pour que chacune ait le m√™me ordre de grandeur.

#### Feature engineering / learning ####

2 m√©thodes :

- feature engineering : Utilisation de la connaissance m√©tier des donn√©es, pour transformer les variables de d√©part (difficile et co√ªteux). 
- feature learning : 
Cr√©ation d'un vecteur de caract√©ristiques (feature vector) de fa√ßon automatique, par aprentissage. L'apprentissage peut √™tre supervis√© ou non supervis√©.


S√©lection des donn√©es minimum n√©cessaires √† l'aprentissage (√©l√©mination des doublons, et des donn√©es non pertinentes). Techniques utilis√©s : PCA, R√©gression des moindres carr√©s partiels dit "R√©gression PLS" (Partial Least Squares regression), analyse factorielle ...

Filtrer le bruit avec des techniques comme : la moyenne mobile (moving average), la Transformation de Fourier (rapide), le filtre de Kalman, un processus autor√©gressif (pour les s√©ries temporelles), un ajustement de courbe (moindre carr√©s, ...)

Pour r√©duire le nombre de features, on peut soit retrouver les dimensions principales, qui peuvent √™tre une combinaison de diff√©rentes observations, ou retrouver la vari√©t√© sous-jacente (manifold). Dans ce dernier cas, on parle de manifold learning.

La r√©duction de dimension permet de r√©soudre plusieurs probl√©matiques :
- le fl√©au de la dimension (curse of dimensionality), qui est la difficult√© d'apprentissage en haute dimension.
- la visualisation des donn√©es. Il difficile de lire un graphique au del√† de 3-4 dimensions
- la r√©duction des co√ªts de calcul, de stockage et d'acquisition des donn√©es.
 
##### Analyse de donn√©es textuelles #####

Plusieurs techniques sont g√©n√©ralement mises en oeuvres pour l'analyse de texte :
- r√©cup√©ration du texte : par scraping ou t√©l√©chargement de fichiers texte.
- tokenisation : s√©paration du texte en mots (unigramme), ou n-gram.
- normalisation :
  * filtrer les caract√®res alphanum√©riques par une regex.
  * suppression des stopwords : les stopwords, sont les mots les plus fr√©quents de la langue (√†, et, de, ...)
  * lemmatisation : remplacement des mots par leur forme canonique (infinitif, masculin singulier, ...)
  * stemming : remplacement des mots par leur racine (suppression des pr√©fixes, suffixes, ...)

On peut repr√©senter un document, par un sac de mots (bag-of-words, ou bag-of-ngrams) :
- en comptant la fr√©quence d'apparition des mots dans le document.
- en pond√©rer cette fr√©quence par rapport √† l'ensemble des documents via tf-idf (Term-Frequency - Inverse Document Frequency)

On peut √©galement repr√©senter un document par un plongement de mots (word embeddings).
Cette m√©thode prend en compte le contexte, en r√©pr√©sentant les mots par des vecteurs, dans un espace avec une forme de similarit√© entre eux (probabiliste).
Par ex. vec("Madrid") - vec("Spain") + vec("France") donne une position dont le vecteur le plus proche est vec("Paris")
On utilisera principalement 2 algos d'apprentissage (word2vec):
- Continuous Bag of Words (CBOW) : entra√Æne le r√©seau de neurones pour pr√©dire un mot en fonction de son contexte (mots avant/apr√®s).
- skip-gram : pr√©diction du contexte en fonction du mot.

word2vec, permet la cr√©ation de word embeddings.

On peut √©galement utiliser d'autres m√©thodes de plongement, tels que [gloVe](https://nlp.stanford.edu/projects/glove/) et [FastText](https://fasttext.cc/). Ou une simple [d√©composition SVD sur une matrice PMI](http://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/)

Entra√Æner son [propre embedding](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/word2vec.ipynb), permet d'avoir un plongement sp√©cifique √† notre corpus (plus performant).

Extraire les informations :
- NER (Named Enity Recognition) : reconna√Ætre des personnes, endroits, entreprises, ...
- Extraction des relations : extraire des relations s√©mantiques (familiales, spatiales)
- Extraction d'√©venements : extraction des actions qui arrivent aux entit√©s ("le pr√©sident √† d√©clar√© X dans son discours", "X a augment√© son CA de 20 %", ...)
- POS Tagging (Part-of-Speech Tagging) : identifier la nature grammatical des mots (nom, verbe, ...)

mod√©lisation de sujet automatique non supervis√©e
- LDA (Latent Dirichlet Allocation)
- NMF (Negative Matrix Factorisation)


#### G√©rer les jeux de donn√©es d√©siquilibr√©s ####

(https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)
- r√©√©chantillonner les donn√©es (over-sampling ou under-sampling)
- stratifier les donn√©es pour la validation crois√©e
- changer l'indicateur de performances


### 2. Cr√©ation du mod√®le ###

Avant d'entrainer le mod√®le, on divise le jeu de donn√©es en portions. Le training set (~80%), et le testing set (~20%). Le testing set ne sera pas utilis√© pour la cr√©ation du mod√®le, mais pour v√©rifier qu'il fonctionne sur de nouvelles donn√©es.

3 principaux algo non-supervis√©s : 
- K-means: Clustering observed features
- Expectation-maximization (EM): Clustering observed and latent features
- Principal components analysis (PCA): Reducing the dimension of the model

La cr√©ation d'un mod√®le supervis√© se fait par optimisation des param√®tres not√©s [ùúΩ](#ùúΩ "theta") de l'ago choisi. L'optimisation consiste √† converger vers le minimum de la fonction loss (perte d'information), en prenant par exemple, la distance euclidienne. Pour cela, on peut minimiser le risque empirique (somme des erreurs constat√©s), ou maximiser la vraissemblance.

#### Bias-variance tradeoff ####

Biais : erreur provenant d‚Äôhypoth√®ses erron√©es. Un biais trop √©lev√© conduit √† un mod√®le trop simpliste, qui ne sera pas repr√©sentatif du comportement observ√©.
Variance : erreur due √† la sensibilit√© aux petites fluctuations de l‚Äô√©chantillon. Une trop grande variance consid√©rera du bruit comme faisant partie du mod√®le.

Overfitting = biais faible et variance √©lev√©e
Underfitting = biais √©lev√© et variance faible

Afin de minimiser l'erreur totale du mod√®le, il faut trouver le compromis biais-variance (bias-variance tradeoff). Ce qui reviens √† trouver un mod√®le ni trop, ni trop peu complexe.
On peut r√©duire la complexit√© d'un mod√®le (et donc sa variance) en r√©duisant les dimensions. On peut √©galement r√©duire la variance en utilisant des m√©thodes ensemblistes, qui combinent et aggr√®gent plusieurs mod√®les √† haute variance.
Avec un mod√®le √† haute variance, on est trop d√©pendant des donn√©es d'entrainement. Tandis qu'avec un mod√®le trop simple, on ne capture pas toute la complexit√© du ph√©nom√®ne.
Une haute variance conduit √† du surapprentissage (overfitting). Alors qu'un biais √©lev√© conduit √† du sous-apprestissage (underfitting).

### 3. √âvaluation du mod√®le ###

#### √âvaluation d'un algorithme de classification binaire ####
On peut utiliser la matrice de confusion qui repr√©sente :
- les vrais positifs ou TP (true positives)
- les vrais n√©gatifs ou TN (true negatives)
- les faux positifs ou FP (false positives) ou erreur de type I
- les faux n√©gatifs ou FN (false negatives) erreur de type II

Validation du mod√®le par des mesures selon des crit√®res de sensibilit√© (appel√© aussi *rappel* ou *recall*), qui est le taux de vrais positifs (TP √∑ nombre r√©els de positifs), et de pr√©cision (TP √∑ nombre de positifs pr√©dits).
La mesure F1 (ou F1 score) est la moyenne harmonique du rappel et de la pr√©cision: 2 x Precision x Rappel √∑ (Precision + Rappel).
On peut √©galement calculer la sp√©cificit√© (taux de vrais n√©gatifs)

On peut utiliser des algo comme le kNN en rempla√ßant une d√©cision √† la majorit√© par une d√©cision au ratio. Il faut alors d√©cider du seuil √† partir duquel attribuer un √©venement √† une classe positive. Pour d√©terminer ce seuil, on peut uiliser la courbe ROC (Receiver-Operator Characteristic). Cette courbe fait correspondre la sensibilit√© et la (anti-)sp√©cificit√©, pour chaque interval de seuil. On choisi ensuite le seuil, en se fixant la sp√©cificit√© ou la sensibilit√© d√©sir√©e.
On peut choisir entre plusieurs mod√®les en comparant leur air sous la courbe, appel√©e AUROC (Area Under the ROC).

On peut √©galement utilis√© la courbe pr√©cision-rappel (PR curve), ou la courbe lift (utilis√© surtout dans le ciblage marketing).

On peut utiliser une approcher na√Øve pour avoir un point de comparaison pour √©valuer des mod√®les. Pour une classification, on peut :
- retourner toujours la m√™me classe
- retourner une classe al√©atoire
- retourner un score al√©atoire,  puis utiliser un seuil.

#### √âvaluation d'un algo de r√©gression ####

On mesure l'erreur moyenne. Avec f(xi), valeur pr√©dite et yi, valeur r√©elle :
- somme des carr√©s des r√©sidus, ou Residual Sum of Squares, RSS = Œ£(f(xi) - yi)¬≤
- erreur quadratique moyenne ou Mean Squared Error, MSE = RSS √∑ n
- Root Mean Squared Error, RMSE = ‚àöMSE
- Root Mean Squared Log Error, RMSLE = ‚àöŒ£(log(f(xi) + 1) - log(yi + 1))¬≤ √∑ n
- erreur carr√© relative, Relative Squared Error, RSE = Œ£(yi - f(xi))¬≤ √∑ Œ£(yi - »≥)¬≤ avec »≥==Œ£yi √∑ n
- le coefficient de d√©termination, R¬≤ = 1 - RSE

#### √âvaluation d'un algorithme ... ####
La qualit√© de l'estimation est estim√©e par validation crois√©e : K-fold cross-validation

Pour s√©lectionner les valeurs des hyperparam√®tres, on fait un grid search, afin de tester toutes les valeurs pertinates. Comme alternative, on peut utiliser "le crit√®re d'information d'Akaike" (Akaike information criterion, AIC) qui repose sur un compromis entre la qualit√© de l'ajustement et la complexit√© du mod√®le.


### 4. Ajustement du mod√®le ###

- lorsque le mod√®le donne de mauvais r√©sultats sur les donn√©es de d'entrainement, on a sous-ajustement des donn√©es (underfitting). Le mod√®le n'a pas r√©ussi √† saisir la relation entre les features et les labels.

- lorsque le mod√®le effectue une bonne pr√©duction sur les donn√©es d'entrainement, mais ne r√©sussi pas sur de nouvelles donn√©es, on a un sur-ajustement (overfittting). Le mod√®le n'a pas r√©ussi √† g√©n√©raliser.

- lorsque le mod√®le est mauvais, √† la fois, sur les donn√©es d'entrainement et de test, on v√©rifiera que la quantit√© de donn√©es est suffisante pour capter la complexit√© du mod√®le.


#### Underfitting

Face √† un sous-ajustement, on essaiera d'ajouter de nouvelles features, ou de trouver des features plus repr√©sentatives. On pourra √©galement diminuer le degr√© de r√©gularisation.

#### Overfitting

Face √† un sur-ajustement, on utilisera moins de features. Et, on augmentera le degr√© de r√©gularisation.


### 5. Utilisation du mod√®le ###

Une fois le mod√®le cr√©√©, on peut r√©aliser des pr√©dictions sur de nouvelles donn√©es.
Ces donn√©es doivent √™tre pr√©par√©s pour pouvoir √™tre trait√©es par le mod√®le, de la m√™me fa√ßon que les donn√©es d'entrainement pour constuire le mod√®le.


## Se former ##

### Se former de z√©ro ###

0. Pr√©-requis en maths
 - [d√©riv√©s](https://www.methodemaths.fr/derivee/)
 - [int√©grales](https://www.methodemaths.fr/integrale/)
 - [probabilit√©s (OC)](https://openclassrooms.com/fr/courses/4525296-maitrisez-les-bases-des-probabilites)
 - Matrices

Pour suivre les cours d'Open Classrooms (OC) sur le Machine Learning, des base en [Python](https://openclassrooms.com/courses/demarrez-votre-projet-avec-python) et en particulier sur les librairies [Numpy, Matplotlib et Pandas](https://openclassrooms.com/courses/decouvrez-les-librairies-python-pour-la-data-science) est recommand√©

1. [Initiez-vous au machine learning (OC)](https://mooc-francophone.com/cours/initiez-vous-au-machine-learning/)
  Pr√©requis : connaissance de C# et XAML recommand√©s
2. [Explorez vos donn√©es avec des algorithmes (OC)](https://mooc-francophone.com/cours/explorez-vos-donnees-avec-des-algorithmes-non-supervises/)
  Pr√©requis : Pyhton, notions d'alg√®bre lin√©aire, notions de probabilit√©s et statistiques.

3. [√âvaluez et am√©liorez les performances d'un mod√®le de machine learning (OC)](https://openclassrooms.com/fr/courses/4297211-evaluez-et-ameliorez-les-performances-dun-modele-de-machine-learning/)
  Pr√©requis : Pyhton, notions d'alg√®bre lin√©aire, notions de probabilit√©s et statistiques.

4. [Entra√Ænez un mod√®le pr√©dictif lin√©aire (OC)](https://openclassrooms.com/fr/courses/4444646-entrainez-un-modele-predictif-lineaire)

5. [Utilisez des mod√®les supervis√©s non lin√©aires (OC)](https://openclassrooms.com/courses/utilisez-des-modeles-supervises-non-lineaires)

6. [Mod√©lisez vos donn√©es avec les m√©thodes ensemblistes (OC)](https://openclassrooms.com/fr/courses/4470521-modelisez-vos-donnees-avec-les-methodes-ensemblistes)

### S'exercer ###

S'entrainer avec Kaggle. Selon Wikip√©dia :
> [Kaggle](https://www.kaggle.com/) est une plateforme web organisant des comp√©titions en science des donn√©es. Sur cette plateforme, les entreprises proposent des probl√®mes en science des donn√©es et offrent un prix aux datalogistes obtenant les meilleures performances.
Kaggle permet √©galement d'obtenir des jeux de donn√©es sans concourir √† une comp√©tition.


Annexe
======

## Codes UTF-8 des symboles

- <a name="ùúΩ">ùúΩ</a>: theta, U+1D73D
- <a name="Œ¶">Œ¶</a>: Phi, u03A6
- <a name="Œ£">Œ£</a>: sigma (somme), u3A3
- <a name="‚àö">‚àö</a>: racine carr√©e, u221A
- <a name="»≥">»≥</a>: y surlign√© (moyenne), u0233
- <a name="√∑">√∑</a>: signe division, u00F7
